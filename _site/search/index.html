<!DOCTYPE html>

<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="generator" content="Jekyll v3.4.3">

		<link rel="stylesheet" href="/css/screen.css">
		<link rel="apple-touch-icon" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
		<link rel="icon" type="image/png" href="/images/favicon.png">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">
		<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

		<!-- Begin Jekyll SEO tag v2.1.0 -->
<title>Search - Base</title>
<meta property="og:title" content="Search" />
<meta name="description" content="Knowledge base template for Jekyll." />
<meta property="og:description" content="Knowledge base template for Jekyll." />
<link rel="canonical" href="https://orange-ape.cloudvent.net//search/" />
<meta property="og:url" content="https://orange-ape.cloudvent.net//search/" />
<meta property="og:site_name" content="Base" />
<script type="application/ld+json">
{"@context": "http://schema.org",
"@type": "WebPage",
"headline": "Search",
"description": "Knowledge base template for Jekyll.",
"publisher": {"@type": "Organization",
"logo": {"@type": "ImageObject",
"url": "https://orange-ape.cloudvent.net//siteicon.png"}},
"url": "https://orange-ape.cloudvent.net//search/"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="https://orange-ape.cloudvent.net//feed.xml" title="Base" />

		
	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
					<a class="nav-toggle" id="open-nav" href="#">&#9776;</a>
<nav>
	<a class="editor-link btn" href="cloudcannon:collections/_data/navigation.yml" class="btn" style="padding: 5px;"><strong>&#9998;</strong> Edit navigation</a>
	
	

		
		<a href="/" class="">Tutorials</a>
	
	

		
		<a href="/videos/" class="">Videos</a>
	
	

		
		<a href="/faq/" class="">FAQ</a>
	
</nav>

				</section>
				<section class="hero_search">
					<h1>Tutorials</h1>
					<p>Everything you need to know about running our software.</p>
					<form action="/search/" method="get">
	<input type="search" name="q"  placeholder="What would you like to know?" autofocus>
	<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
	<input type="submit" value="Search" style="display: none;">
</form>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>
<ul id="search-results"></ul>

<script>
	window.data = {
		
			
				
					
					
					"recommender-word2vec": {
						"id": "recommender-word2vec",
						"title": "Word2Vec",
						"categories": "Recommender",
						"url": " /recommender/Word2Vec/",
						"content": ""
					}
					
				
			
		
			
				
					,
					
					"statistics-statistical-tests": {
						"id": "statistics-statistical-tests",
						"title": "Statistical tests",
						"categories": "Statistics",
						"url": " /statistics/Statistical-tests/",
						"content": ""
					}
					
				
			
		
			
				
					,
					
					"etl-pymongo": {
						"id": "etl-pymongo",
						"title": "PyMongo",
						"categories": "ETL",
						"url": " /etl/PyMongo/",
						"content": ""
					}
					
				
			
		
			
				
					,
					
					"recommender-deep-learning": {
						"id": "recommender-deep-learning",
						"title": "Deep Neural Networds",
						"categories": "Recommender",
						"url": " /recommender/Deep-Learning/",
						"content": ""
					}
					
				
			
		
			
				
					,
					
					"recommender-collaborative-filtering": {
						"id": "recommender-collaborative-filtering",
						"title": "Collaborative Filtering",
						"categories": "Recommender",
						"url": " /recommender/Collaborative-Filtering/",
						"content": ""
					}
					
				
			
		
			
				
					,
					
					"statistics-ab-testing": {
						"id": "statistics-ab-testing",
						"title": "A/B Testing",
						"categories": "Statistics",
						"url": " /statistics/AB-testing/",
						"content": ""
					}
					
				
			
		
			
				
					,
					
					"pandas-convert-pandas-dataframe-to-dictionary": {
						"id": "pandas-convert-pandas-dataframe-to-dictionary",
						"title": "DataFrame to Dictionary",
						"categories": "Pandas",
						"url": " /pandas/Convert-Pandas-DataFrame-to-Dictionary/",
						"content": "to_dict() method\n\nConsider the following simple DataFrame:\n\nimport pandas as pd\ndf=pd.DataFrame(\n{'Users':['a','b'],'Events':[5,75]},index=['0','1'])\ndf\n\n\n\n\n\n\n  \n    \n      \n      Events\n      Users\n    \n  \n  \n    \n      0\n      5\n      a\n    \n    \n      1\n      75\n      b\n    \n  \n\n\n\nto_dict() converts it into a dictionary.\n\ndf.to_dict()\n\n\n\n{'Events': {'0': 5, '1': 75}, 'Users': {'0': 'a', '1': 'b'}}\n\n\n\nSpecify the return orientation\n\ndict is the default format as shown above.\n\nIn case a different dictionary format is needed, here are examples of the possible orient arguments:\n\nlist - Keys of the converted dictionary are columns names, values are lists of column data\n\ndf.to_dict('list')\n\n\n\n{'Events': [5, 75], 'Users': ['a', 'b']}\n\n\n\nseries - like list while values are Series\n\ndf.to_dict('series')\n\n\n\n{'Events': 0     5\n 1    75\n Name: Events, dtype: int64, 'Users': 0    a\n 1    b\n Name: Users, dtype: object}\n\n\n\nsplit - splits columns, data and index as keys\n\ndf.to_dict('split')\n\n\n\n{'columns': ['Events', 'Users'],\n 'data': [[5, 'a'], [75, 'b']],\n 'index': ['0', '1']}\n\n\n\nrecords - each row becomes a dictionary where key is the column name and value is the data in the cell\n\ndf.to_dict('records')\n\n\n\n[{'Events': 5, 'Users': 'a'}, {'Events': 75, 'Users': 'b'}]\n\n\n\nindex - like records, but a dictionary of dictionaries with keys as index labels (rather than a list)\n\ndf.to_dict('index')\n\n\n\n{'0': {'Events': 5, 'Users': 'a'}, '1': {'Events': 75, 'Users': 'b'}}"
					}
					
				
			
		
			
				
					,
					
					"python-default-parameter-values": {
						"id": "python-default-parameter-values",
						"title": "Default Parameter Values",
						"categories": "Python",
						"url": " /python/Default-parameter-values/",
						"content": "Let’s have an example of what this post is going to talk about:\n\ndef foo(a=[]):\n    a.append(5)\n    return a\n\n\n\nfoo()\n\n\n\n[5]\n\n\n\nfoo()\n\n\n\n[5, 5]\n\n\n\nfoo()\n\n\n\n[5, 5, 5]\n\n\n\nThis happens because\n\n\n  Default parameter values are evaluated when the function definition is executed.\n\n\nThis means that the expression is evaluated once, when the function is defined, and that the same “pre-computed” value is used for each call.\n\nThis is especially important to understand when a default parameter is a mutable object, such as a list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default value is in effect modified.\n\nA way around this is to use None as the default, and explicitly test for it in the body of the function.\n\ndef foo(a=None):\n    if a==None:\n        a=[]\n    else:\n        a.append(5)\n    return a\n\n\n\nfoo()\n\n\n\n[]\n\n\n\nfoo()\n\n\n\n[]\n\n\n\nfoo()\n\n\n\n[]"
					}
					
				
			
		
			
				
					,
					
					"machine-learning-cross-validation": {
						"id": "machine-learning-cross-validation",
						"title": "Cross Validation",
						"categories": "Machine-Learning",
						"url": " /machine-learning/Cross-Validation/",
						"content": "What is cross-validation?\n\nIt’s a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set.\n\nIt’s common to find that our model performs differently depending on the subset of the data it’s trained on. This phenomenon is known as overfitting: The model is learning to classify the training set so well that it doesn’t generalize and perform well on data it hasn’t seen before.\n\nSo we split the original data set into k subsets, use one of the subsets as the testing set, and the rest of the subsets are used as the training set. This process is then repeated k times such that each subset is used as the testing set exactly once.\n\nThis process is what we called cross-validation.\n\nExamples: leave-one-out cross validation, K-fold cross validation\n\nHow to do it right?\n\nFirstly, the training and validation data sets should be drawn from the same population.\n\npredicting stock prices: trained for a certain 5-year period, it’s unrealistic to treat the subsequent 5-year a draw from the same population\ncommon mistake: for instance the step of choosing the kernel parameters of a SVM should be cross-validated as well\n\nBias-variance trade-off for k-fold cross validation\n\nLeave-one-out cross-validation: gives approximately unbiased estimates of the test error since each training set contains almost the entire data set (n−1 observations).\n\nBut: we average the outputs of n fitted models, each of which is trained on an almost identical set of observations hence the outputs are highly correlated. Since the variance of a mean of quantities increases when correlation of these quantities increase, the test error estimate from a LOOCV has higher variance than the one obtained with k-fold cross validation\n\nTypically, we choose k=5 or k=10, as these values have been shown empirically to yield test error estimates that suffer neither from excessively high bias nor high variance.\n\nRobust or accurate algorithms, how do you choose?\n\nSimpler models are preferred if more complex models do not significantly improve the quality of the description for the observations.\n\nOur ultimate goal is to design systems with good generalization capacity, that is, systems that correctly identify patterns in data instances not seen before. While the generalization performance of a learning system strongly depends on the complexity of the model assumed.\n\nIf the model is too simple, the system can only capture the actual data regularities in a rough manner. In this case, the system has poor generalization properties and is said to suffer from underfitting.\n\nBy contrast, if the model is too complex, the system can identify accidental patterns in the training data that need not be present in the test set. These spurious patterns can be the result of random fluctuations or of measurement errors during the data collection process. In this case, the generalization capacity of the learning system is also poor. The learning system is said to be affected by overfitting. Spurious patterns, which are only present by accident in the data, tend to have complex forms.\n\nBy the way, ensemble learning can help balancing bias/variance. Several weak learners together = strong learner.\n\nHow do you select metrics?\n\nClassification\n\n\n  \n    Recall / Sensitivity / True positive rate\n  \n  \n    Precision / Positive Predictive value\n  \n  \n    Specificity / True negative rate\n  \n  \n    Accuracy\n  \n  \n    ROC / AUC\n  \n\n\nROC is a graphical plot that illustrates the performance of a binary classifier (SensitivitySensitivity Vs 1−Specificity1−Specificity or SensitivitySensitivity Vs SpecificitySpecificity). They are not sensitive to unbalanced classes.\nAUC is the area under the ROC curve. Perfect classifier: AUC=1, fall on (0,1); 100% sensitivity (no FN) and 100% specificity (no FP)\n\n\n  Logarithmic loss\n\n\nPunishes infinitely the deviation from the true value! It’s better to be somewhat wrong than emphatically wrong!\n\n\n  \n    Misclassification Rate\n  \n  \n    F1-Score\n  \n\n\nRegression\n\n\n  Mean Squared Error Vs Mean Absolute Error\n\n\nRMSE gives a relatively high weight to large errors. The RMSE is most useful when large errors are particularly undesirable.\n\nThe MAE is a linear score: all the individual differences are weighted equally in the average. MAE is more robust to outliers than MSE.\n\n\n  Root Mean Squared Logarithmic Error\n\n\nRMSLE penalizes an under-predicted estimate greater than an over-predicted estimate (opposite to RMSE)\n\n\n  Weighted Mean Absolute Error\n\n\nThe weighted average of absolute errors. MAE and RMSE consider that each prediction provides equally precise information about the error variation, i.e. the standard variation of the error term is constant over all the predictions. Examples: recommender systems (differences between past and recent products)"
					}
					
				
			
		
	};
</script>
<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script>
			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="edit-footer"><a class="editor-link btn" href="cloudcannon:collections/_data/footer.yml" class="btn" style="padding: 5px;"><strong>&#9998;</strong> Edit footer</a></p>
		<ul class="footer-links">
			
				<li><a target="_blank" href="https://facebook.com/" class="Facebook-icon">
					
						
		<svg class="facebook" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M19,4V7H17A1,1 0 0,0 16,8V10H19V13H16V20H13V13H11V10H13V7.5C13,5.56 14.57,4 16.5,4M20,2H4A2,2 0 0,0 2,4V20A2,2 0 0,0 4,22H20A2,2 0 0,0 22,20V4C22,2.89 21.1,2 20,2Z" /></svg>
	

					
					</a></li>
			
				<li><a target="_blank" href="https://twitter.com/" class="Twitter-icon">
					
						
		<svg class="twitter" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M22.46,6C21.69,6.35 20.86,6.58 20,6.69C20.88,6.16 21.56,5.32 21.88,4.31C21.05,4.81 20.13,5.16 19.16,5.36C18.37,4.5 17.26,4 16,4C13.65,4 11.73,5.92 11.73,8.29C11.73,8.63 11.77,8.96 11.84,9.27C8.28,9.09 5.11,7.38 3,4.79C2.63,5.42 2.42,6.16 2.42,6.94C2.42,8.43 3.17,9.75 4.33,10.5C3.62,10.5 2.96,10.3 2.38,10C2.38,10 2.38,10 2.38,10.03C2.38,12.11 3.86,13.85 5.82,14.24C5.46,14.34 5.08,14.39 4.69,14.39C4.42,14.39 4.15,14.36 3.89,14.31C4.43,16 6,17.26 7.89,17.29C6.43,18.45 4.58,19.13 2.56,19.13C2.22,19.13 1.88,19.11 1.54,19.07C3.44,20.29 5.7,21 8.12,21C16,21 20.33,14.46 20.33,8.79C20.33,8.6 20.33,8.42 20.32,8.23C21.16,7.63 21.88,6.87 22.46,6Z" /></svg>
	

					
					</a></li>
			
				<li><a target="_blank" href="https://youtube.com/" class="YouTube-icon">
					
						
		<svg class="youtube" fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M10,16.5V7.5L16,12M20,4.4C19.4,4.2 15.7,4 12,4C8.3,4 4.6,4.19 4,4.38C2.44,4.9 2,8.4 2,12C2,15.59 2.44,19.1 4,19.61C4.6,19.81 8.3,20 12,20C15.7,20 19.4,19.81 20,19.61C21.56,19.1 22,15.59 22,12C22,8.4 21.56,4.91 20,4.4Z" /></svg>
	

					
					</a></li>
			
				<li><a  href="/feed.xml" class="RSS-icon">
					
						
		<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"/><circle cx="6.18" cy="17.82" r="2.18"/><path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/></svg>
		

					
					</a></li>
			
		</ul>
		<p class="copyright">&copy; Base 2018. All rights reserved.</p>
	</div>
</footer>
		<script>
			$(function() {
				$('a[href*=\\#]').not(".no-smooth").on('click', function(event){
					var el = $(this.hash);
					if (el.length > 0) {
						// event.preventDefault();
						$('html,body').animate({scrollTop:$(this.hash).offset().top - 50}, 500);
					}
				});

				$('svg').click(function() {
					$(this).parent('form').submit();
				});
			});

			document.getElementById("open-nav").addEventListener("click", function (event) {
				event.preventDefault();
				document.body.classList.toggle("nav-open");
			});
		</script>
		
	</body>
</html>
